{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyMfvq3MDnRGSp/mYfNcgOL4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/gdrive', force_remount=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"z_shzULYCMNO","executionInfo":{"status":"ok","timestamp":1701185354235,"user_tz":-60,"elapsed":18757,"user":{"displayName":"Erikas Mikuzis","userId":"02233197238408831535"}},"outputId":"0de84fb8-8ae5-42f5-8097-6da2aaea1ca4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","from torchvision import models\n","from torch.nn.functional import relu\n","import torch.nn.functional as F\n","\n","from torch.utils.data import Dataset\n","from PIL import Image\n","import numpy as np\n","\n","class CustomDataset(Dataset):\n","    def __init__(self, image_paths, label_paths):\n","        self.image_paths = image_paths\n","        self.label_paths = label_paths\n","\n","    def __len__(self):\n","        return len(self.image_paths)\n","\n","    def __getitem__(self, idx):\n","        # Load the image\n","        image = Image.open(self.image_paths[idx])\n","        np_image = np.array(image, dtype=np.float32)\n","\n","        # Normalize the image\n","        normalized_image = np_image / 65535.0  # For 16-bit images\n","\n","        # Load and process the label data\n","        label_image = Image.open(self.label_paths[idx])\n","        label_array = np.array(label_image, dtype=np.float32)\n","\n","        grayscale_to_class_mapping = {0: 0, 128: 1, 255: 2} # a set that maps gray-levels to a class\n","\n","        # Map grayscale values to class labels\n","        mapped_labels = np.copy(label_array)\n","        for grayscale_value, class_id in grayscale_to_class_mapping.items():\n","            mapped_labels[label_array == grayscale_value] = class_id\n","\n","        # Convert to PyTorch tensors\n","        image_tensor = torch.from_numpy(normalized_image).unsqueeze(0) # unsqueeze to enable channel dimension, was gone due to being a grayscale image\n","        label_tensor = torch.from_numpy(mapped_labels)\n","\n","        return image_tensor, label_tensor\n"],"metadata":{"id":"SsaNvjjhCMLH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["### Label images ###\n","# white class - 255 nickel\n","# gray class - 128 ysz\n","# black class - 0 pores\n","\n","class UNet(nn.Module):\n","    def __init__(self, n_class):\n","        super().__init__()\n","\n","        # Define a helper function for creating a block\n","        def conv_block(in_channels, out_channels):\n","            return nn.Sequential(\n","                nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n","                nn.BatchNorm2d(out_channels),\n","                nn.ReLU(),\n","                nn.Dropout(p=0.1)\n","            )\n","\n","        # Encoder\n","        self.e11 = conv_block(1, 64)\n","        self.e12 = conv_block(64, 64)\n","        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n","\n","        self.e21 = conv_block(64, 128)\n","        self.e22 = conv_block(128, 128)\n","        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n","\n","        self.e31 = conv_block(128, 256)\n","        self.e32 = conv_block(256, 256)\n","        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n","\n","        self.e41 = conv_block(256, 512)\n","        self.e42 = conv_block(512, 512)\n","        self.pool4 = nn.MaxPool2d(kernel_size=2, stride=2)\n","\n","        self.e51 = conv_block(512, 1024)\n","        self.e52 = conv_block(1024, 1024)\n","\n","        # Decoder\n","        self.upconv1 = nn.ConvTranspose2d(1024, 512, kernel_size=2, stride=2)\n","        self.d11 = conv_block(1024, 512)\n","        self.d12 = conv_block(512, 512)\n","\n","        self.upconv2 = nn.ConvTranspose2d(512, 256, kernel_size=2, stride=2)\n","        self.d21 = conv_block(512, 256)\n","        self.d22 = conv_block(256, 256)\n","\n","        self.upconv3 = nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2)\n","        self.d31 = conv_block(256, 128)\n","        self.d32 = conv_block(128, 128)\n","\n","        self.upconv4 = nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2)\n","        self.d41 = conv_block(128, 64)\n","        self.d42 = conv_block(64, 64)\n","\n","        # Output layer\n","        self.outconv = nn.Conv2d(64, n_class, kernel_size=1)\n","\n","    def forward(self, x):\n","        # Encoder\n","        xe11 = self.e11(x)\n","        xe12 = self.e12(xe11)\n","        xp1 = self.pool1(xe12)\n","\n","        xe21 = self.e21(xp1)\n","        xe22 = self.e22(xe21)\n","        xp2 = self.pool2(xe22)\n","\n","        xe31 = self.e31(xp2)\n","        xe32 = self.e32(xe31)\n","        xp3 = self.pool3(xe32)\n","\n","        xe41 = self.e41(xp3)\n","        xe42 = self.e42(xe41)\n","        xp4 = self.pool4(xe42)\n","\n","        xe51 = self.e51(xp4)\n","        xe52 = self.e52(xe51)\n","\n","        # Decoder\n","        xu1 = self.upconv1(xe52)\n","        xu11 = torch.cat([xu1, xe42], dim=1)\n","        xd11 = self.d11(xu11)\n","        xd12 = self.d12(xd11)\n","\n","        xu2 = self.upconv2(xd12)\n","        xu22 = torch.cat([xu2, xe32], dim=1)\n","        xd21 = self.d21(xu22)\n","        xd22 = self.d22(xd21)\n","\n","        xu3 = self.upconv3(xd22)\n","        xu33 = torch.cat([xu3, xe22], dim=1)\n","        xd31 = self.d31(xu33)\n","        xd32 = self.d32(xd31)\n","\n","        xu4 = self.upconv4(xd32)\n","        xu44 = torch.cat([xu4, xe12], dim=1)\n","        xd41 = self.d41(xu44)\n","        xd42 = self.d42(xd41)\n","\n","        # Output layer\n","        out = self.outconv(xd42)\n","\n","        return out"],"metadata":{"id":"28Q8Ds-fCMIt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from torch.utils.data import DataLoader, random_split\n","from torch import optim\n","import torch\n","import os\n","import matplotlib.pyplot as plt\n","\n","def dice_coefficient(predicted, target, num_classes):\n","    dice_scores = []  # To store dice coefficient for each class\n","\n","    # Convert predictions and targets to one-hot encoded form\n","    predicted_one_hot = F.one_hot(predicted, num_classes).permute(0, 3, 1, 2).float()\n","    target_one_hot = F.one_hot(target, num_classes).permute(0, 3, 1, 2).float()\n","\n","    # Calculate Dice coefficient for each class\n","    for class_index in range(num_classes):\n","        intersection = (predicted_one_hot[:, class_index, :, :] * target_one_hot[:, class_index, :, :]).sum()\n","        union = predicted_one_hot[:, class_index, :, :].sum() + target_one_hot[:, class_index, :, :].sum()\n","        dice_score = (2 * intersection + 1e-6) / (union + 1e-6)  # Adding a small epsilon to avoid division by zero\n","        dice_scores.append(dice_score)\n","\n","    # Average Dice score across all classes\n","    avg_dice_score = sum(dice_scores) / len(dice_scores)\n","    return avg_dice_score.item()  # Return the value as a Python scalar\n","\n","def get_image_paths(data_dir, label_dir):\n","    data_paths = [os.path.join(data_dir, img) for img in sorted(os.listdir(data_dir))]\n","    label_paths = [os.path.join(label_dir, lbl) for lbl in sorted(os.listdir(label_dir))]\n","    return data_paths, label_paths\n","\n","def create_subsets(dataset, subset_sizes):\n","    subsets = {}\n","    for size in subset_sizes:\n","        if size == len(dataset):\n","            subsets[size] = dataset  # Use the full dataset\n","        else:\n","            subset, _ = random_split(dataset, [size, len(dataset) - size])\n","            subsets[size] = subset\n","    return subsets\n"],"metadata":{"id":"Qu4BYsfPCMGU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Define your dataset paths\n","data_dir = '/content/gdrive/MyDrive/training_dataset/data_crop64/'\n","label_dir = '/content/gdrive/MyDrive/training_dataset/label_crop64/'\n","\n","# Get image paths and create the full dataset\n","image_paths, label_paths = get_image_paths(data_dir, label_dir)\n","dataset = CustomDataset(image_paths=image_paths, label_paths=label_paths)\n","\n","# Define subset sizes including the full dataset size\n","subset_sizes = [50, 125, 250, len(dataset)]  # Add the full dataset size\n","\n","# Create subsets\n","dataset_subsets = create_subsets(dataset, subset_sizes)\n","\n","# Device setup\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(f\"Using {device}\")\n","\n","# Training configurations\n","learning_rate = 0.001\n","num_epochs = 250  # Adjust as needed\n","\n","# Define early stopping parameters\n","patience = 10  # Number of epochs to wait for improvement\n","min_delta = 0.0005  # Minimum change to signify an improvement\n","best_loss = float('inf')  # Initialize best loss to a high value\n","epochs_no_improve = 0  # Counter for epochs with no improvement\n","\n","# Loop over subsets and train the model\n","for size, subset in dataset_subsets.items():\n","    print(f\"\\nTraining on subset size: {size}\")\n","\n","    # Initialize early stopping parameters for each subset\n","    best_loss = float('inf')\n","    epochs_no_improve = 0\n","\n","    # Split the subset into training, validation, and test datasets\n","    train_size = int(0.70 * len(subset))\n","    val_size = int(0.15 * len(subset))\n","    test_size = len(subset) - train_size - val_size\n","    train_dataset, val_dataset, test_dataset = random_split(subset, [train_size, val_size, test_size])\n","\n","    # DataLoader setup\n","    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n","    val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n","    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n","\n","    # Model, loss function, and optimizer setup\n","    model = UNet(n_class=3).to(device)\n","    criterion = torch.nn.CrossEntropyLoss()\n","    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n","\n","    # Training loop\n","    for epoch in range(num_epochs):\n","        model.train()\n","        for batch_idx, (images, labels) in enumerate(train_loader):\n","            images, labels = images.to(device), labels.to(device)\n","\n","            optimizer.zero_grad()\n","            outputs = model(images)\n","            labels = labels.squeeze(1).long()\n","            loss = criterion(outputs, labels)\n","            loss.backward()\n","            optimizer.step()\n","\n","            if batch_idx % 10 == 0:\n","                print(f\"Epoch {epoch+1}/{num_epochs}, Batch {batch_idx+1}/{len(train_loader)}, Loss: {loss.item()}\")\n","\n","        # Validation phase\n","        model.eval()\n","        val_loss = 0\n","        with torch.no_grad():\n","            val_loss = 0\n","            for images, labels in val_loader:\n","                images, labels = images.to(device), labels.to(device)\n","                outputs = model(images)\n","                labels = labels.squeeze(1).long()\n","                loss = criterion(outputs, labels)\n","                val_loss += loss.item()\n","            val_loss /= len(val_loader)\n","            print(f\"Validation Loss after Epoch {epoch+1}: {val_loss}\")\n","\n","        # Early stopping logic\n","        if val_loss < best_loss - min_delta:\n","            best_loss = val_loss\n","            epochs_no_improve = 0\n","        else:\n","            epochs_no_improve += 1\n","\n","        if epochs_no_improve == patience:\n","            print(f\"Early stopping triggered at epoch {epoch+1}\")\n","            break\n","\n","    model.eval()  # Set model to evaluation mode\n","    with torch.no_grad():\n","        test_loss = 0\n","        correct = 0\n","        total = 0\n","        dice_scores = []\n","\n","        for images, labels in test_loader:\n","            images, labels = images.to(device), labels.to(device)\n","            outputs = model(images)\n","            probabilities = F.softmax(outputs, dim=1)\n","            _, predicted = torch.max(probabilities, 1)\n","            labels = labels.squeeze(1).long()\n","\n","            loss = criterion(outputs, labels)\n","            test_loss += loss.item()\n","            total += labels.numel()\n","            correct += (predicted == labels).sum().item()\n","\n","            dice_score = dice_coefficient(predicted, labels, num_classes=3)\n","            dice_scores.append(dice_score)\n","\n","        test_loss /= len(test_loader)\n","        test_accuracy = 100 * correct / total\n","        average_dice_score = sum(dice_scores) / len(dice_scores)\n","\n","        print(f\"Subset size {size} - Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.2f}%, Average Dice Score: {average_dice_score:.4f}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4lezj3KQCMED","outputId":"864289b1-68c8-4529-a6bb-dac6aac829e7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Using cpu\n","\n","Training on subset size: 50\n","Epoch 1/250, Batch 1/2, Loss: 1.1347191333770752\n","Validation Loss after Epoch 1: 1.1025564670562744\n","Epoch 2/250, Batch 1/2, Loss: 0.4978398382663727\n","Validation Loss after Epoch 2: 1.0688583850860596\n","Epoch 3/250, Batch 1/2, Loss: 0.32562294602394104\n","Validation Loss after Epoch 3: 1.0120784044265747\n","Epoch 4/250, Batch 1/2, Loss: 0.2987369894981384\n","Validation Loss after Epoch 4: 1.0047296285629272\n"]}]},{"cell_type":"code","source":["torch.save(model.state_dict(), '64x64smaller_subsets_with_Early_Stoppage.pth')"],"metadata":{"id":"5nn08jWleapb"},"execution_count":null,"outputs":[]}]}